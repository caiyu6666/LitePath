{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09b0c33d",
   "metadata": {},
   "source": [
    "# Inference of a single pathology patch using LiteFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52195723",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import get_model\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8d014da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ycaibt/anaconda3/envs/torch/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1024])\n"
     ]
    }
   ],
   "source": [
    "# LiteFM in the LitePath can be used as a patch-level feature extractor.\n",
    "device = torch.device('cuda')\n",
    "x = torch.randn(1, 3, 224, 224).to(device)\n",
    "model = get_model('LiteFM', device)\n",
    "feat = model(x)\n",
    "print(feat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374d7d96",
   "metadata": {},
   "source": [
    "# Inference of LitePath pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce62baea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from litepath_deploy import ModelDeployment\n",
    "from models import DAttention, AdaPatchSelector, get_custom_transformer\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "from preprocessing.create_patches_fp import mp_seg_and_patch, seg_and_patch\n",
    "from datasets import PatchDataset\n",
    "\n",
    "from preprocessing.extract_images_and_pack2h5 import read_images, get_wsi_path, read_images_parallel\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler, Subset\n",
    "from multiprocessing.pool import Pool\n",
    "import json\n",
    "\n",
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c05ea79",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8339bd",
   "metadata": {},
   "source": [
    "### Get Coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "842b6266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source:  examples/Lung_NSCLC_Subtyping/slides/\n",
      "patch_save_dir:  examples/Lung_NSCLC_Subtyping/patches/coords_h5\n",
      "mask_save_dir:  examples/Lung_NSCLC_Subtyping/patches/masks\n",
      "stitch_save_dir:  examples/Lung_NSCLC_Subtyping/patches/stitches\n",
      "source : examples/Lung_NSCLC_Subtyping/slides/\n",
      "save_dir : examples/Lung_NSCLC_Subtyping/patches\n",
      "patch_save_dir : examples/Lung_NSCLC_Subtyping/patches/coords_h5\n",
      "mask_save_dir : examples/Lung_NSCLC_Subtyping/patches/masks\n",
      "stitch_save_dir : examples/Lung_NSCLC_Subtyping/patches/stitches\n",
      "{'seg_params': {'seg_level': np.int64(-1), 'sthresh': np.int64(8), 'mthresh': np.int64(7), 'close': np.int64(4), 'use_otsu': np.True_, 'keep_ids': 'none', 'exclude_ids': 'none'}, 'filter_params': {'a_t': np.int64(16), 'a_h': np.int64(4), 'max_n_holes': np.int64(8)}, 'patch_params': {'use_padding': np.True_, 'contour_fn': 'four_pt'}, 'vis_params': {'vis_level': np.int64(-1), 'line_thickness': np.int64(100)}}\n",
      "{'source': 'examples/Lung_NSCLC_Subtyping/slides/', 'save_dir': 'examples/Lung_NSCLC_Subtyping/patches', 'patch_save_dir': 'examples/Lung_NSCLC_Subtyping/patches/coords_h5', 'mask_save_dir': 'examples/Lung_NSCLC_Subtyping/patches/masks', 'stitch_save_dir': 'examples/Lung_NSCLC_Subtyping/patches/stitches'}\n",
      "Total: 2\n",
      "\n",
      "\n",
      "progress: 0.00, 0/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing examples/Lung_NSCLC_Subtyping/slides/1028189.svs\n",
      "####################################################################################################\n",
      "levels: ((77688, 46977), (19422, 11744), (4855, 2936), (2427, 1468))\n",
      "mpp: 0.503, object_power: 20x, patch_size: 256, step_size: 256\n",
      "####################################################################################################\n",
      "Performing segmentation\n",
      "Creating patches for:  1028189 ...\n",
      "Total number of contours to process:  3\n",
      "Bounding Box: 66324 18016 10852 13697\n",
      "Contour Area: 62042336.0\n",
      "Extracted 997 coordinates\n",
      "Bounding Box: 57713 16288 9668 14657\n",
      "Contour Area: 85740368.0\n",
      "Extracted 1382 coordinates\n",
      "Bounding Box: 16965 10144 17734 25089\n",
      "Contour Area: 268604208.0\n",
      "Extracted 4197 coordinates\n",
      "segmentation took 0.399716854095459 seconds\n",
      "patching took 0.43612051010131836 seconds\n",
      "stitching took -1 seconds\n",
      "\n",
      "\n",
      "progress: 0.50, 1/2\n",
      "processing examples/Lung_NSCLC_Subtyping/slides/1019708.svs\n",
      "####################################################################################################\n",
      "levels: ((89640, 46366), (22410, 11591), (5602, 2897), (2801, 1448))\n",
      "mpp: 0.503, object_power: 20x, patch_size: 256, step_size: 256\n",
      "####################################################################################################\n",
      "Performing segmentation\n",
      "Creating patches for:  1019708 ...\n",
      "Total number of contours to process:  5\n",
      "Bounding Box: 75494 11591 7874 31253\n",
      "Contour Area: 137087967.0\n",
      "Extracted 1892 coordinates\n",
      "Bounding Box: 50468 10246 5057 8134\n",
      "Contour Area: 10731168.0\n",
      "Extracted 237 coordinates\n",
      "Bounding Box: 73286 6596 7970 4580\n",
      "Contour Area: 17459745.0\n",
      "Extracted 304 coordinates\n",
      "Bounding Box: 1728 4835 36324 40187\n",
      "Contour Area: 667103449.0\n",
      "Extracted 9137 coordinates\n",
      "Bounding Box: 43011 0 45669 43485\n",
      "Contour Area: 989697593.0\n",
      "Extracted 15298 coordinates\n",
      "segmentation took 0.46964144706726074 seconds\n",
      "patching took 1.818124532699585 seconds\n",
      "stitching took -1 seconds\n",
      "average segmentation time in s per slide: 0.43467915058135986\n",
      "average patching time in s per slide: 1.1271225214004517\n",
      "average stiching time in s per slide: -1.0\n"
     ]
    }
   ],
   "source": [
    "task = 'Lung_NSCLC_Subtyping'\n",
    "wsi_format = 'svs'\n",
    "\n",
    "wsi_dir = f\"examples/{task}/slides/\"\n",
    "save_dir = f\"examples/{task}/patches\"\n",
    "preset = 'tcga.csv'\n",
    "use_mp = False\n",
    "patch_save_dir = os.path.join(save_dir, \"coords_h5\")\n",
    "mask_save_dir = os.path.join(save_dir, \"masks\")\n",
    "stitch_save_dir = os.path.join(save_dir, \"stitches\")\n",
    "\n",
    "seg = True\n",
    "patch = True\n",
    "stitch = False\n",
    "patch_level = 0\n",
    "patch_size = 256\n",
    "step_size = 256\n",
    "auto_skip = True\n",
    "\n",
    "process_list = None\n",
    "\n",
    "print(\"source: \", wsi_dir)\n",
    "print(\"patch_save_dir: \", patch_save_dir)\n",
    "print(\"mask_save_dir: \", mask_save_dir)\n",
    "print(\"stitch_save_dir: \", stitch_save_dir)\n",
    "\n",
    "directories = {\"source\": wsi_dir, \"save_dir\": save_dir, \"patch_save_dir\": patch_save_dir, \"mask_save_dir\": mask_save_dir, \"stitch_save_dir\": stitch_save_dir}\n",
    "\n",
    "for key, val in directories.items():\n",
    "    print(\"{} : {}\".format(key, val))\n",
    "    if key not in [\"source\"]:\n",
    "        os.makedirs(val, exist_ok=True)\n",
    "\n",
    "seg_params = {\"seg_level\": -1, \"sthresh\": 8, \"mthresh\": 7, \"close\": 4, \"use_otsu\": False, \"keep_ids\": \"none\", \"exclude_ids\": \"none\"}\n",
    "filter_params = {\"a_t\": 100, \"a_h\": 16, \"max_n_holes\": 32}\n",
    "vis_params = {\"vis_level\": -1, \"line_thickness\": 120}\n",
    "patch_params = {\"use_padding\": True, \"contour_fn\": \"four_pt\"}\n",
    "\n",
    "if preset:\n",
    "    preset_df = pd.read_csv(os.path.join(\"presets\", preset))\n",
    "    for key in seg_params.keys():\n",
    "        seg_params[key] = preset_df.loc[0, key]\n",
    "\n",
    "    for key in filter_params.keys():\n",
    "        filter_params[key] = preset_df.loc[0, key]\n",
    "\n",
    "    for key in vis_params.keys():\n",
    "        vis_params[key] = preset_df.loc[0, key]\n",
    "\n",
    "    for key in patch_params.keys():\n",
    "        patch_params[key] = preset_df.loc[0, key]\n",
    "\n",
    "parameters = {\"seg_params\": seg_params, \"filter_params\": filter_params, \"patch_params\": patch_params, \"vis_params\": vis_params}\n",
    "\n",
    "print(parameters)\n",
    "print(directories)\n",
    "if use_mp:\n",
    "    fn = mp_seg_and_patch\n",
    "else:\n",
    "    fn = seg_and_patch\n",
    "seg_times, patch_times = fn(**directories, **parameters, patch_size=patch_size, step_size=step_size, seg=seg, use_default_params=False, save_mask=True, \n",
    "                            stitch=stitch, patch_level=patch_level, patch=patch, process_list=process_list, \n",
    "                            auto_skip=auto_skip, wsi_format=wsi_format)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbcea98",
   "metadata": {},
   "source": [
    "### Crop images and pack to h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a1e0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:Processing:  examples/Lung_NSCLC_Subtyping/patches/coords_h5/1019708.h5examples/Lung_NSCLC_Subtyping/patches/coords_h5/1028189.h5  examples/Lung_NSCLC_Subtyping/slides/1019708.svsexamples/Lung_NSCLC_Subtyping/slides/1028189.svs\n",
      "\n",
      "examples/Lung_NSCLC_Subtyping/slides/1028189.svs finished!\n",
      "examples/Lung_NSCLC_Subtyping/slides/1019708.svs finished!\n",
      "All slides have been cropped!\n"
     ]
    }
   ],
   "source": [
    "wsi_format = 'svs'\n",
    "h5_root = f\"examples/{task}/patches/coords_h5\"\n",
    "save_root = f\"examples/{task}/packed_images\"\n",
    "wsi_root = f\"examples/{task}/slides\"\n",
    "os.makedirs(save_root, exist_ok=True)\n",
    "cpu_cores = 6\n",
    "\n",
    "h5_files = os.listdir(h5_root)\n",
    "h5_paths = [os.path.join(h5_root, p) for p in h5_files]\n",
    "wsi_paths = get_wsi_path(wsi_root, h5_files, wsi_format)\n",
    "save_roots = [os.path.join(save_root, i) for i in h5_files]\n",
    "\n",
    "# args = [(h5, sr, wsi_path) for h5, wsi_path, sr in zip(h5_paths, wsi_paths, save_roots)]\n",
    "# mp = Pool(cpu_cores)\n",
    "# mp.map(read_images, args)\n",
    "# print('All slides have been cropped!')\n",
    "\n",
    "for h5, wsi_path, sr in zip(h5_paths, wsi_paths, save_roots):\n",
    "    read_images_parallel((h5, sr, wsi_path), num_workers=cpu_cores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa7dc9e",
   "metadata": {},
   "source": [
    "### Data loader preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "389a5267",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'Lung_NSCLC_Subtyping'\n",
    "labels = ['LUSC', 'LUAD']\n",
    "with open('examples/selection.json', 'r') as f:\n",
    "    selection = json.load(f)\n",
    "\n",
    "selection_number = selection[task]\n",
    "k_u, k_a = selection_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "275708c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ycaibt/anaconda3/envs/torch/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "img_id = \"1019708\"\n",
    "# img_id = \"1028189\"\n",
    "img_root = f\"examples/{task}/packed_images\"\n",
    "slide_path = f\"{img_root}/{img_id}.h5\"\n",
    "\n",
    "transform = get_custom_transformer('litefm')\n",
    "case_dataset = PatchDataset(slide_path, transform=transform, load_to_memory=False)  \n",
    "# load_to_memory: preload all patches to memory to accelerate the inference. Need more memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53fd066d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_patches = len(case_dataset)\n",
    "uniform_indices = torch.linspace(0, num_patches-1, steps=k_u).int()\n",
    "# 除去uniform_indices之外的索引\n",
    "all_indices = torch.arange(num_patches)\n",
    "mask = ~torch.isin(all_indices, uniform_indices)  # 创建布尔掩码，非 uniform_indices 的索引为 True\n",
    "remaining_indices = all_indices[mask]  # 选取布尔掩码中为 True 的索引\n",
    "\n",
    "uniform_loader = torch.utils.data.DataLoader(Subset(case_dataset, uniform_indices), batch_size=256, shuffle=False, num_workers=32) if k_u > 0 else None\n",
    "attention_loader = torch.utils.data.DataLoader(Subset(case_dataset, remaining_indices), batch_size=256, shuffle=False, num_workers=32) if k_a > 0 else None\n",
    "# Note: Suitable num_workers are important for the inference speed. We set it to 32 for the example in RTX 3090."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca493d9",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0616b7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded APS model from examples/Lung_NSCLC_Subtyping/models/aps_model_best.pth.tar\n",
      "Loaded MIL model from examples/Lung_NSCLC_Subtyping/models/model_best.pth.tar\n",
      "batch_size: 256, k_a: 100, k_u: 1900, Buffer threshold: 2500\n"
     ]
    }
   ],
   "source": [
    "aps_ckpt = f\"examples/{task}/models/aps_model_best.pth.tar\"\n",
    "mil_ckpt = f\"examples/{task}/models/model_best.pth.tar\"\n",
    "deployer = ModelDeployment('LiteFM', n_classes=2, k_a=k_a, k_u=k_u, aps_ckpt=aps_ckpt, mil_ckpt=mil_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c9bbe0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform features shape: torch.Size([1900, 1024]), time cost: 2.721139907836914\n",
      "Attention features shape: torch.Size([100, 1024]), time cost: 6.701376914978027\n",
      "MIL model inference time cost: 0.04475545883178711\n",
      "Prediction: LUSC, Probability: 0.9450033903121948\n"
     ]
    }
   ],
   "source": [
    "logits, prob, pred = deployer.infer_litepath(uniform_loader, attention_loader)\n",
    "print(f\"Prediction: {labels[pred]}, Probability: {prob[0][pred[0]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0de660d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26868, 1900, 100)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_patches, k_u, k_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7bf346",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
